import streamlit as st
from supabase import create_client
import pandas as pd
from io import BytesIO
from openpyxl import load_workbook
import time
import requests
from urllib.parse import urlparse, urlunparse
from datetime import datetime
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

# -----------------------
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# -----------------------
st.set_page_config(page_title="SEO Index Manager", layout="wide")

# ==========================================
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
# ==========================================

TASK_POST = "/v3/serp/google/organic/task_post"
TASK_GET_ADV = "/v3/serp/google/organic/task_get/advanced/{task_id}"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
if "selected_project_id" not in st.session_state:
    st.session_state.selected_project_id = None
if "selected_folder_id" not in st.session_state:
    st.session_state.selected_folder_id = None # None = –º—ã –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞, ID = –º—ã –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏

@st.cache_resource
def init_supabase():
    url = st.secrets["supabase"]["url"]
    key = st.secrets["supabase"]["key"]
    return create_client(url, key)

def init_requests():
    s = requests.Session()
    s.auth = (st.secrets["dataforseo"]["login"], st.secrets["dataforseo"]["password"])
    s.headers.update({"Content-Type": "application/json"})
    return s

try:
    supabase = init_supabase()
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
    st.stop()

# -----------------------
# –•–ï–õ–ü–ï–†–´ (Slack, Excel, Parsing)
# -----------------------
def send_slack_file(file_bytes, filename, message):
    try:
        if "slack" in st.secrets:
            token = st.secrets["slack"].get("bot_token")
            channel = st.secrets["slack"].get("channel_id")
            if token and channel:
                client = WebClient(token=token)
                client.files_upload_v2(
                    channel=channel, file=file_bytes, filename=filename, title=filename, initial_comment=message
                )
                st.success("‚úÖ –û—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Slack!")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ Slack: {e}")

def generate_excel_report(df, sheet_name="Report"):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name[:30])
    return output.getvalue()

def norm_url(u: str) -> str:
    p = urlparse(u.strip())
    netloc = (p.netloc or "").lower()
    if netloc.startswith("www."): netloc = netloc[4:]
    path = (p.path or "").rstrip("/")
    return urlunparse(("", netloc, path, "", "", "")).lower()

def build_site_query(url: str) -> str:
    p = urlparse(url.strip())
    host = (p.netloc or "").lower()
    if host.startswith("www."): host = host[4:]
    path = (p.path or "").strip().lstrip("/").rstrip("/")
    return f"site:{host}" if path in ("", "/") else f"site:{host}/{path}"

def match_indexed(original_url: str, items):
    orig = norm_url(original_url)
    for it in items:
        if it.get("type") == "organic":
            u = it.get("url")
            if u and norm_url(u) == orig: return True
    return False

def parse_text_urls(text_input):
    urls = []
    if not text_input: return urls
    lines = text_input.split('\n')
    for line in lines:
        line = line.strip()
        if line and (line.startswith("http://") or line.startswith("https://")):
            urls.append(line)
    return urls

# -----------------------
# –õ–û–ì–ò–ö–ê –ü–†–û–í–ï–†–ö–ò
# -----------------------
def run_check(links_data, report_name="Report"):
    if not links_data: return
    session = init_requests()
    host = st.secrets["dataforseo"].get("host", "api.dataforseo.com").replace("https://", "")
    base_url = f"https://{host}"
    
    progress_bar = st.progress(0.0)
    status_text = st.empty()
    payload = []
    tasks_map = {} 
    
    for item in links_data:
        payload.append({
            "location_code": 2840, "language_code": "en", "depth": 10,
            "keyword": build_site_query(item['url'])
        })

    BATCH_SIZE = 50
    total = len(links_data)
    processed = 0
    
    for i in range(0, total, BATCH_SIZE):
        batch_links = links_data[i : i + BATCH_SIZE]
        batch_payload = payload[i : i + BATCH_SIZE]
        status_text.write(f"üì§ –û–±—Ä–∞–±–æ—Ç–∫–∞ {i+1}-{min(i+BATCH_SIZE, total)} –∏–∑ {total}...")
        
        try:
            r = session.post(base_url + TASK_POST, json=batch_payload, timeout=60)
            res = r.json()
            if res.get('status_code') == 20000:
                batch_ids = []
                for idx, task in enumerate(res.get('tasks', [])):
                    if task.get('id'):
                        tid = task['id']
                        tasks_map[tid] = batch_links[idx]['id']
                        batch_ids.append(tid)
                
                if not batch_ids: 
                    processed += len(batch_links)
                    continue
                
                time.sleep(2)
                status_text.write("‚è≥ –ê–Ω–∞–ª–∏–∑...")
                
                for tid in batch_ids:
                    try:
                        r_get = session.get(base_url + TASK_GET_ADV.format(task_id=tid), timeout=30)
                        d_get = r_get.json()
                        link_id = tasks_map[tid]
                        url_obj = next(l for l in batch_links if l['id'] == link_id)
                        
                        task_res = (d_get.get('tasks') or [{}])[0]
                        if task_res.get('status_code') == 20000:
                            items = (task_res.get('result') or [{}])[0].get('items', [])
                            is_ind = match_indexed(url_obj['url'], items)
                            supabase.table("links").update({
                                "status": "done", "is_indexed": is_ind, 
                                "last_check": datetime.utcnow().isoformat(), "task_id": tid
                            }).eq("id", link_id).execute()
                        else:
                            supabase.table("links").update({"status": "error"}).eq("id", link_id).execute()
                    except: pass
            else:
                st.error(f"API Error: {res.get('status_message')}")
            
            processed += len(batch_links)
            progress_bar.progress(processed / total)
        except Exception as e:
            st.error(f"Net Error: {e}")
        time.sleep(1.5)

    status_text.success("‚úÖ –ì–æ—Ç–æ–≤–æ!")
    time.sleep(1)
    st.rerun()

# ==========================================
# –ò–ù–¢–ï–†–§–ï–ô–°
# ==========================================

# --- –°–ê–ô–î–ë–ê–† ---
with st.sidebar:
    st.title("üóÇ –ù–∞–≤–∏–≥–∞—Ü–∏—è")
    
    # –ö–Ω–æ–ø–∫–∞ –¥–æ–º–æ–π
    if st.button("üè† –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã", use_container_width=True):
        st.session_state.selected_project_id = None
        st.session_state.selected_folder_id = None
        st.rerun()
    
    st.divider()
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤
    projs = supabase.table("projects").select("*").order("created_at", desc=True).execute().data
    
    st.caption("–ü—Ä–æ–µ–∫—Ç—ã:")
    if projs:
        for p in projs:
            is_active = (st.session_state.selected_project_id == p['id'])
            btn_type = "primary" if is_active else "secondary"
            if st.button(f"üìÇ {p['name']}", key=f"p_{p['id']}", use_container_width=True, type=btn_type):
                st.session_state.selected_project_id = p['id']
                st.session_state.selected_folder_id = None # –°–±—Ä–æ—Å –ø–∞–ø–∫–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
                st.rerun()
                
    st.divider()
    with st.expander("‚ûï –°–æ–∑–¥–∞—Ç—å –ü—Ä–æ–µ–∫—Ç"):
        new_p = st.text_input("–ò–º—è –ø—Ä–æ–µ–∫—Ç–∞")
        if st.button("–°–æ–∑–¥–∞—Ç—å"):
            supabase.table("projects").insert({"name": new_p}).execute()
            st.rerun()

# --- –õ–û–ì–ò–ö–ê –û–¢–û–ë–†–ê–ñ–ï–ù–ò–Ø ---

# 1. –ì–õ–ê–í–ù–ê–Ø (–î–ê–®–ë–û–†–î –í–°–ï–• –ü–†–û–ï–ö–¢–û–í)
if not st.session_state.selected_project_id:
    st.title("üìä –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã")
    if not projs:
        st.info("–ù–µ—Ç –ø—Ä–æ–µ–∫—Ç–æ–≤. –°–æ–∑–¥–∞–π—Ç–µ –ø–µ—Ä–≤—ã–π –≤ –º–µ–Ω—é —Å–ª–µ–≤–∞.")
    else:
        # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        all_links = supabase.table("links").select("id").execute().data
        st.metric("–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫ –≤ —Å–∏—Å—Ç–µ–º–µ", len(all_links))
        st.write("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç —Å–ª–µ–≤–∞, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É.")

# 2. –ü–†–û–°–ú–û–¢–† –ü–†–û–ï–ö–¢–ê (–°–ü–ò–°–û–ö –ü–ê–ü–û–ö)
elif st.session_state.selected_project_id and st.session_state.selected_folder_id is None:
    # –î–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞
    curr_proj = next(p for p in projs if p['id'] == st.session_state.selected_project_id)
    st.title(f"üìÇ {curr_proj['name']}")
    st.caption("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞–ø–∫–∏
    folders = supabase.table("folders").select("*").eq("project_id", curr_proj['id']).order("created_at", desc=False).execute().data
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Å—ã–ª–æ–∫
    links_res = supabase.table("links").select("folder_id, status, is_indexed").eq("project_id", curr_proj['id']).execute()
    df_links = pd.DataFrame(links_res.data)
    
    # --- –ö–ê–†–¢–û–ß–ö–ò –ü–ê–ü–û–ö ---
    # 1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–≤–æ–¥–∏–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏
    if folders:
        for f in folders:
            # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –ø–∞–ø–∫–∏
            if not df_links.empty:
                f_links = df_links[df_links['folder_id'] == f['id']]
                total = len(f_links)
                indexed = len(f_links[f_links['is_indexed'] == True])
            else:
                total, indexed = 0, 0
            
            with st.container(border=True):
                c1, c2, c3 = st.columns([3, 1, 1])
                with c1:
                    st.subheader(f"üìÅ {f['name']}")
                    st.caption(f"–°—Å—ã–ª–æ–∫: {total} | –í –∏–Ω–¥–µ–∫—Å–µ: {indexed}")
                with c3:
                    st.write("")
                    # –ö–ù–û–ü–ö–ê –í–•–û–î–ê –í –ü–ê–ü–ö–£
                    if st.button("–û—Ç–∫—Ä—ã—Ç—å ‚û°", key=f"open_{f['id']}", use_container_width=True):
                        st.session_state.selected_folder_id = f['id']
                        st.rerun()
    
    # 2. –ö–∞—Ä—Ç–æ—á–∫–∞ "General" (—Å—Å—ã–ª–∫–∏ –±–µ–∑ –ø–∞–ø–∫–∏)
    gen_links = df_links[df_links['folder_id'].isnull()] if not df_links.empty else pd.DataFrame()
    if not gen_links.empty:
        with st.container(border=True):
            c1, c2, c3 = st.columns([3, 1, 1])
            with c1:
                st.subheader("üìÑ General (–ë–µ–∑ –ø–∞–ø–∫–∏)")
                st.caption(f"–°—Å—ã–ª–æ–∫: {len(gen_links)}")
            with c3:
                st.write("")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º ID -1 –¥–ª—è –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è "General"
                if st.button("–û—Ç–∫—Ä—ã—Ç—å ‚û°", key="open_general", use_container_width=True):
                    st.session_state.selected_folder_id = -1
                    st.rerun()

    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –ø–∞–ø–∫–∏
    st.divider()
    with st.popover("‚ûï –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –ø–∞–ø–∫—É"):
        new_f_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏")
        if st.button("–°–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É"):
            supabase.table("folders").insert({"name": new_f_name, "project_id": curr_proj['id']}).execute()
            st.rerun()
            
    # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    st.write("---")
    if not df_links.empty:
        pending = len(df_links[df_links['status'] == 'pending'])
        if pending > 0:
            if st.button(f"üöÄ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç ({pending} –≤ –æ—á–µ—Ä–µ–¥–∏)", type="primary"):
                 to_check = supabase.table("links").select("id, url").eq("project_id", curr_proj['id']).eq("status", "pending").execute().data
                 run_check(to_check)

# 3. –í–ù–£–¢–†–ò –ü–ê–ü–ö–ò (–î–ï–¢–ê–õ–¨–ù–´–ô –í–ò–î)
elif st.session_state.selected_folder_id is not None:
    curr_proj = next(p for p in projs if p['id'] == st.session_state.selected_project_id)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é –ø–∞–ø–∫—É
    if st.session_state.selected_folder_id == -1:
        folder_name = "General (–ë–µ–∑ –ø–∞–ø–∫–∏)"
        folder_db_id = None # –î–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –ë–î
    else:
        # –ò—â–µ–º –∏–º—è –ø–∞–ø–∫–∏ –≤ –ë–î
        f_res = supabase.table("folders").select("*").eq("id", st.session_state.selected_folder_id).execute().data
        if not f_res:
            st.error("–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            st.stop()
        folder_name = f_res[0]['name']
        folder_db_id = st.session_state.selected_folder_id

    # –•–µ–¥–µ—Ä –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    col_back, col_title = st.columns([1, 5])
    with col_back:
        if st.button("‚¨Ö –ù–∞–∑–∞–¥"):
            st.session_state.selected_folder_id = None
            st.rerun()
    with col_title:
        st.title(f"{curr_proj['name']} / {folder_name}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Å—ã–ª–æ–∫ –ø–∞–ø–∫–∏
    query = supabase.table("links").select("*").eq("project_id", curr_proj['id'])
    if folder_db_id is None:
        query = query.is_("folder_id", "null")
    else:
        query = query.eq("folder_id", folder_db_id)
    
    links = query.order("id", desc=True).execute().data
    df = pd.DataFrame(links)

    if df.empty:
        st.info("–í —ç—Ç–æ–π –ø–∞–ø–∫–µ –ø–æ–∫–∞ –ø—É—Å—Ç–æ.")
    else:
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–∞–ø–∫–∏
        total = len(df)
        indexed = len(df[df['is_indexed'] == True])
        pending = len(df[df['status'] == 'pending'])
        
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("–í—Å–µ–≥–æ", total)
        m2.metric("–í –∏–Ω–¥–µ–∫—Å–µ", f"{indexed} ({(indexed/total*100):.1f}%)")
        m3.metric("–û—á–µ—Ä–µ–¥—å", pending)
        
        with m4:
            if pending > 0:
                if st.button("üöÄ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —ç—Ç—É –ø–∞–ø–∫—É", type="primary"):
                    to_check = df[df['status'] == 'pending'][['id', 'url']].to_dict('records')
                    run_check(to_check)
            else:
                if st.button("üîÑ –ü–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞–ø–∫—É"):
                    # –°–±—Ä–æ—Å —Å—Ç–∞—Ç—É—Å–æ–≤ —Ç–æ–ª—å–∫–æ —ç—Ç–æ–π –ø–∞–ø–∫–∏
                    ids = df['id'].tolist()
                    supabase.table("links").update({"status": "pending", "is_indexed": None}).in_("id", ids).execute()
                    st.rerun()

        # –¢–∞–±–ª–∏—Ü–∞
        st.write("")
        selection = st.dataframe(
            df[['url', 'status', 'is_indexed', 'last_check']],
            use_container_width=True,
            on_select="rerun",
            selection_mode="multi-row",
            column_config={
                "is_indexed": st.column_config.CheckboxColumn("Index?", disabled=True),
                "url": st.column_config.LinkColumn("URL")
            }
        )
        
        # –£–¥–∞–ª–µ–Ω–∏–µ
        if len(selection.selection.rows) > 0:
            sel_idx = selection.selection.rows
            sel_ids = df.iloc[sel_idx]['id'].tolist()
            if st.button(f"üóë –£–¥–∞–ª–∏—Ç—å {len(sel_ids)} —Å—Å—ã–ª–æ–∫"):
                supabase.table("links").delete().in_("id", sel_ids).execute()
                st.rerun()

    st.divider()
    
    # --- –ë–õ–û–ö –î–û–ë–ê–í–õ–ï–ù–ò–Ø –°–°–´–õ–û–ö –í –≠–¢–£ –ü–ê–ü–ö–£ ---
    st.subheader(f"üì• –î–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫–∏ –≤ '{folder_name}'")
    text_input = st.text_area("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫–∏ —Å–ø–∏—Å–∫–æ–º:", height=100)
    if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
        urls = parse_text_urls(text_input)
        if urls:
            data = [{
                "project_id": curr_proj['id'],
                "url": u,
                "folder_id": folder_db_id, # –í—Å—Ç–∞–≤–ª—è–µ–º —Å—Ä–∞–∑—É –≤ —Ç–µ–∫—É—â—É—é –ø–∞–ø–∫—É
                "status": "pending"
            } for u in urls]
            
            # –í—Å—Ç–∞–≤–∫–∞ –±–∞—Ç—á–∞–º–∏
            batch_size = 500
            for i in range(0, len(data), batch_size):
                supabase.table("links").insert(data[i:i+batch_size]).execute()
            
            st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(urls)} —Å—Å—ã–ª–æ–∫!")
            time.sleep(1)
            st.rerun()
