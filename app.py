import streamlit as st
from supabase import create_client
import pandas as pd
from io import BytesIO
from openpyxl import load_workbook
import time
import requests
from urllib.parse import urlparse, urlunparse
from datetime import datetime
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

# -----------------------
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# -----------------------
st.set_page_config(page_title="Link Checker", layout="wide")

# ==========================================
# üåç –°–ò–°–¢–ï–ú–ê –ü–ï–†–ï–í–û–î–û–í (LOCALIZATION)
# ==========================================

if "lang" not in st.session_state:
    st.session_state.lang = "en"  # Default language

TRANSLATIONS = {
    "en": {
        "nav_title": "Navigation",
        "home_btn": "üè† HOME (All Projects)",
        "projects_list": "Your Projects:",
        "view_proj": "üìä View Project",
        "general_folder": "üìÑ General (No Folder)",
        "create_proj_exp": "‚ûï Create Project",
        "proj_name_placeholder": "Project Name",
        "create_btn": "Create",
        "del_proj_exp": "üóë Delete Current Project",
        "del_proj_confirm": "Yes, Delete Project",
        "dash_title": "üìä All Projects",
        "no_projs": "No projects found. Create one in the sidebar.",
        "total_projs": "Total Projects",
        "total_queue": "TOTAL IN QUEUE",
        "ready_global": "Ready to check: **{}** links across all projects.",
        "run_global": "üöÄ RUN CHECK FOR ALL PROJECTS",
        "queue_empty": "Queue is empty.",
        "reset_global": "üîÑ Reset statuses in ALL PROJECTS and re-check",
        "folder_struct": "Folder Structure:",
        "flat_mode": "No folders in this project. Working in flat mode.",
        "create_first_folder": "‚ûï Create first folder",
        "root_folder": "Root Folder",
        "back_to_proj": "‚¨Ö Back to Project",
        "back_to_folders": "‚¨Ö Back to Folders",
        "empty_folder": "This folder is empty.",
        "total": "Total",
        "indexed": "Indexed",
        "queue": "Queue",
        "run_queue": "üöÄ Check Queue",
        "rerun_all": "üîÑ Re-check All",
        "del_selected": "üóë Delete {} links",
        "add_links_title": "üì• Add links to '{}'",
        "paste_links": "Paste links list:",
        "save_btn": "üíæ Save",
        "success_added": "‚úÖ Added {} links!",
        "open_btn": "Open ‚û°",
        "del_btn": "üóë",
        "del_folder_btn": "üóë Delete",
        "folder_name": "Folder Name",
        "create_folder_btn": "Create Folder",
        "add_new_folder": "‚ûï Add New Folder",
        "processing": "üì§ Processing {}-{} of {}...",
        "analyzing": "‚è≥ Analyzing...",
        "sending_report": "üìä Sending report...",
        "done": "‚úÖ Done!",
        "slack_success": "‚úÖ Report sent to Slack!",
        "slack_error": "‚ùå Slack Error: {}",
        "report_msg": "‚úÖ *Check Completed ({})!*\nüîó Total: {}",
        "col_url": "URL",
        "col_index": "Indexed?",
        "col_status": "Status",
        "col_date": "Last Check",
        "warn_del_proj": "Warning! This will delete the project and ALL links inside.",
        "confirm_del": "Yes, delete",
        "project": "Project",
        "links_count": "Links count",
        "in_index": "In Index",
        "in_queue": "In Queue",
        "db_error_retry": "‚ö†Ô∏è DB Connection failed. Retrying..."
    },
    "uk": {
        "nav_title": "–ù–∞–≤—ñ–≥–∞—Ü—ñ—è",
        "home_btn": "üè† –ì–û–õ–û–í–ù–ê (–í—Å—ñ –ø—Ä–æ–µ–∫—Ç–∏)",
        "projects_list": "–í–∞—à—ñ –ø—Ä–æ–µ–∫—Ç–∏:",
        "view_proj": "üìä –û–≥–ª—è–¥ –ø—Ä–æ–µ–∫—Ç—É",
        "general_folder": "üìÑ –ó–∞–≥–∞–ª—å–Ω–∞ (–ë–µ–∑ –ø–∞–ø–∫–∏)",
        "create_proj_exp": "‚ûï –°—Ç–≤–æ—Ä–∏—Ç–∏ –ü—Ä–æ–µ–∫—Ç",
        "proj_name_placeholder": "–ù–∞–∑–≤–∞ –ø—Ä–æ–µ–∫—Ç—É",
        "create_btn": "–°—Ç–≤–æ—Ä–∏—Ç–∏",
        "del_proj_exp": "üóë –í–∏–¥–∞–ª–∏—Ç–∏ –ø–æ—Ç–æ—á–Ω–∏–π –ø—Ä–æ–µ–∫—Ç",
        "del_proj_confirm": "–¢–∞–∫, –≤–∏–¥–∞–ª–∏—Ç–∏ –ø—Ä–æ–µ–∫—Ç",
        "dash_title": "üìä –í—Å—ñ –ø—Ä–æ–µ–∫—Ç–∏",
        "no_projs": "–ù–µ–º–∞—î –ø—Ä–æ–µ–∫—Ç—ñ–≤. –°—Ç–≤–æ—Ä—ñ—Ç—å –ø–µ—Ä—à–∏–π —É –º–µ–Ω—é –∑–ª—ñ–≤–∞.",
        "total_projs": "–í—Å—å–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—ñ–≤",
        "total_queue": "–í–°–¨–û–ì–û –í –ß–ï–†–ó–Ü",
        "ready_global": "–ì–æ—Ç–æ–≤–æ –¥–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏: **{}** –ø–æ—Å–∏–ª–∞–Ω—å —É –≤—Å—ñ—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö.",
        "run_global": "üöÄ –ó–ê–ü–£–°–¢–ò–¢–ò –ü–ï–†–ï–í–Ü–†–ö–£ –í–°–Ü–• –ü–†–û–ï–ö–¢–Ü–í",
        "queue_empty": "–ß–µ—Ä–≥–∞ –ø—É—Å—Ç–∞.",
        "reset_global": "üîÑ –°–∫–∏–Ω—É—Ç–∏ —Å—Ç–∞—Ç—É—Å–∏ —É –í–°–Ü–• –ü–†–û–ï–ö–¢–ê–• —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏",
        "folder_struct": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫:",
        "flat_mode": "–£ —Ü—å–æ–º—É –ø—Ä–æ–µ–∫—Ç—ñ –Ω–µ–º–∞—î –ø–∞–ø–æ–∫. –ü—Ä–∞—Ü—é—î–º–æ —É –ø—Ä–æ—Å—Ç–æ–º—É —Ä–µ–∂–∏–º—ñ.",
        "create_first_folder": "‚ûï –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–µ—Ä—à—É –ø–∞–ø–∫—É",
        "root_folder": "–ö–æ—Ä–µ–Ω–µ–≤–∞ –ø–∞–ø–∫–∞",
        "back_to_proj": "‚¨Ö –î–æ –ø—Ä–æ–µ–∫—Ç—É",
        "back_to_folders": "‚¨Ö –î–æ –ø–∞–ø–æ–∫",
        "empty_folder": "–£ —Ü—ñ–π –ø–∞–ø—Ü—ñ –ø–æ–∫–∏ –ø–æ—Ä–æ–∂–Ω—å–æ.",
        "total": "–í—Å—å–æ–≥–æ",
        "indexed": "–í —ñ–Ω–¥–µ–∫—Å—ñ",
        "queue": "–ß–µ—Ä–≥–∞",
        "run_queue": "üöÄ –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–µ—Ä–≥—É",
        "rerun_all": "üîÑ –ü–µ—Ä–µ–ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –≤—Å–µ",
        "del_selected": "üóë –í–∏–¥–∞–ª–∏—Ç–∏ {} –ø–æ—Å–∏–ª–∞–Ω—å",
        "add_links_title": "üì• –î–æ–¥–∞—Ç–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –≤ '{}'",
        "paste_links": "–í—Å—Ç–∞–≤—Ç–µ —Å–ø–∏—Å–æ–∫ –ø–æ—Å–∏–ª–∞–Ω—å:",
        "save_btn": "üíæ –ó–±–µ—Ä–µ–≥—Ç–∏",
        "success_added": "‚úÖ –î–æ–¥–∞–Ω–æ {} –ø–æ—Å–∏–ª–∞–Ω—å!",
        "open_btn": "–í—ñ–¥–∫—Ä–∏—Ç–∏ ‚û°",
        "del_btn": "üóë",
        "del_folder_btn": "üóë –í–∏–¥–∞–ª–∏—Ç–∏",
        "folder_name": "–ù–∞–∑–≤–∞ –ø–∞–ø–∫–∏",
        "create_folder_btn": "–°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–∞–ø–∫—É",
        "add_new_folder": "‚ûï –î–æ–¥–∞—Ç–∏ –Ω–æ–≤—É –ø–∞–ø–∫—É",
        "processing": "üì§ –û–±—Ä–æ–±–∫–∞ {}-{} –∑ {}...",
        "analyzing": "‚è≥ –ê–Ω–∞–ª—ñ–∑...",
        "sending_report": "üìä –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –∑–≤—ñ—Ç—É...",
        "done": "‚úÖ –ì–æ—Ç–æ–≤–æ!",
        "slack_success": "‚úÖ –ó–≤—ñ—Ç –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Slack!",
        "slack_error": "‚ùå –ü–æ–º–∏–ª–∫–∞ Slack: {}",
        "report_msg": "‚úÖ *–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({})!*\nüîó –í—Å—å–æ–≥–æ: {}",
        "col_url": "URL",
        "col_index": "–Ü–Ω–¥–µ–∫—Å?",
        "col_status": "–°—Ç–∞—Ç—É—Å",
        "col_date": "–î–∞—Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏",
        "warn_del_proj": "–£–≤–∞–≥–∞! –¶–µ –≤–∏–¥–∞–ª–∏—Ç—å –ø—Ä–æ–µ–∫—Ç —ñ –í–°–Ü –ø–æ—Å–∏–ª–∞–Ω–Ω—è –≤ –Ω—å–æ–º—É.",
        "confirm_del": "–¢–∞–∫, –≤–∏–¥–∞–ª–∏—Ç–∏",
        "project": "–ü—Ä–æ–µ–∫—Ç",
        "links_count": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å",
        "in_index": "–í —ñ–Ω–¥–µ–∫—Å—ñ",
        "in_queue": "–í —á–µ—Ä–∑—ñ",
        "db_error_retry": "‚ö†Ô∏è –ó'—î–¥–Ω–∞–Ω–Ω—è –∑ –ë–î –≤—Ç—Ä–∞—á–µ–Ω–æ. –ü–æ–≤—Ç–æ—Ä–Ω–∞ —Å–ø—Ä–æ–±–∞..."
    }
}

def t(key):
    """Helper to get translation"""
    lang = st.session_state.lang
    return TRANSLATIONS[lang].get(key, key)

# ==========================================
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
# ==========================================

TASK_POST = "/v3/serp/google/organic/task_post"
TASK_GET_ADV = "/v3/serp/google/organic/task_get/advanced/{task_id}"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
if "selected_project_id" not in st.session_state:
    st.session_state.selected_project_id = None
if "selected_folder_id" not in st.session_state:
    st.session_state.selected_folder_id = None 

@st.cache_resource
def init_supabase():
    url = st.secrets["supabase"]["url"]
    key = st.secrets["supabase"]["key"]
    return create_client(url, key)

def init_requests():
    s = requests.Session()
    s.auth = (st.secrets["dataforseo"]["login"], st.secrets["dataforseo"]["password"])
    s.headers.update({"Content-Type": "application/json"})
    return s

try:
    supabase = init_supabase()
except Exception as e:
    st.error(f"DB Connection Error: {e}")
    st.stop()

# -----------------------
# –•–ï–õ–ü–ï–†–´
# -----------------------
def send_slack_file(file_bytes, filename, message):
    try:
        if "slack" in st.secrets:
            token = st.secrets["slack"].get("bot_token")
            channel = st.secrets["slack"].get("channel_id")
            if token and channel:
                client = WebClient(token=token)
                client.files_upload_v2(
                    channel=channel, file=file_bytes, filename=filename, title=filename, initial_comment=message
                )
                st.success(t("slack_success"))
    except Exception as e:
        st.error(t("slack_error").format(e))

def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Report')
    return output.getvalue()

def norm_url(u: str) -> str:
    p = urlparse(u.strip())
    netloc = (p.netloc or "").lower()
    if netloc.startswith("www."): netloc = netloc[4:]
    path = (p.path or "").rstrip("/")
    return urlunparse(("", netloc, path, "", "", "")).lower()

def build_site_query(url: str) -> str:
    p = urlparse(url.strip())
    host = (p.netloc or "").lower()
    if host.startswith("www."): host = host[4:]
    path = (p.path or "").strip().lstrip("/").rstrip("/")
    return f"site:{host}" if path in ("", "/") else f"site:{host}/{path}"

def match_indexed(original_url: str, items):
    orig = norm_url(original_url)
    for it in items:
        if it.get("type") == "organic":
            u = it.get("url")
            if u and norm_url(u) == orig: return True
    return False

def parse_text_urls(text_input):
    urls = []
    if not text_input: return urls
    lines = text_input.split('\n')
    for line in lines:
        line = line.strip()
        if line and (line.startswith("http://") or line.startswith("https://")):
            urls.append(line)
    return urls

# –§—É–Ω–∫—Ü–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–±–æ–µ–≤ —Å–µ—Ç–∏ (Retry)
def safe_fetch(table, select="*", order_col=None):
    try:
        query = supabase.table(table).select(select)
        if order_col:
            query = query.order(order_col, desc=(order_col == "created_at"))
        return query.execute().data
    except Exception as e:
        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞, –∂–¥–µ–º –∏ –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
        time.sleep(1)
        try:
            query = supabase.table(table).select(select)
            if order_col:
                query = query.order(order_col, desc=(order_col == "created_at"))
            return query.execute().data
        except Exception as e2:
            st.error(f"Failed to fetch data: {e2}")
            return []

# -----------------------
# –õ–û–ì–ò–ö–ê –ü–†–û–í–ï–†–ö–ò
# -----------------------
def run_check(links_data, report_name_prefix="Report"):
    """
    Main function for checking links via DataForSEO.
    Handles:
    - 20000: Success (Check items for index)
    - 40102: No Search Results (Not Indexed)
    - 40601/40602: Polling (Wait and retry)
    """
    if not links_data: return
    session = init_requests()
    host = st.secrets["dataforseo"].get("host", "api.dataforseo.com").replace("https://", "")
    base_url = f"https://{host}"
    
    progress_bar = st.progress(0.0)
    status_text = st.empty()
    payload = []
    tasks_map = {} 
    
    # 1. Prepare payload
    for item in links_data:
        payload.append({
            "location_code": 2840, 
            "language_code": "en", 
            "depth": 10,
            "keyword": build_site_query(item['url'])
        })

    BATCH_SIZE = 50
    total = len(links_data)
    processed = 0
    
    # 2. Batch processing
    for i in range(0, total, BATCH_SIZE):
        batch_links = links_data[i : i + BATCH_SIZE]
        batch_payload = payload[i : i + BATCH_SIZE]
        
        msg_proc = t("processing").format(i+1, min(i+BATCH_SIZE, total), total)
        status_text.write(msg_proc)
        
        try:
            # --- STEP 1: POST TASKS ---
            r = session.post(base_url + TASK_POST, json=batch_payload, timeout=60)
            res = r.json()
            
            if res.get('status_code') == 20000:
                batch_ids = []
                for idx, task in enumerate(res.get('tasks', [])):
                    if task.get('id'):
                        tid = task['id']
                        tasks_map[tid] = batch_links[idx]['id']
                        batch_ids.append(tid)
                
                if not batch_ids: 
                    processed += len(batch_links)
                    continue

                # --- STEP 2: POLLING LOOP ---
                for tid in batch_ids:
                    link_id = tasks_map[tid]
                    max_retries = 10 
                    retry_delay = 3   
                    
                    for attempt in range(max_retries):
                        try:
                            # Get Task Result
                            r_get = session.get(base_url + TASK_GET_ADV.format(task_id=tid), timeout=30)
                            d_get = r_get.json()
                            
                            task_res = (d_get.get('tasks') or [{}])[0]
                            status_code = task_res.get('status_code')

                            # CASE A: Success (20000) -> Check if URL is in results
                            if status_code == 20000:
                                items = (task_res.get('result') or [{}])[0].get('items', [])
                                url_obj = next(l for l in batch_links if l['id'] == link_id)
                                is_ind = match_indexed(url_obj['url'], items)
                                
                                supabase.table("links").update({
                                    "status": "done", 
                                    "is_indexed": is_ind, 
                                    "last_check": datetime.utcnow().isoformat(), 
                                    "task_id": tid
                                }).eq("id", link_id).execute()
                                break 

                            # CASE B: No Search Results (40102) -> Definitely Not Indexed
                            elif status_code == 40102:
                                supabase.table("links").update({
                                    "status": "done", 
                                    "is_indexed": False,  # Explicitly False
                                    "last_check": datetime.utcnow().isoformat(), 
                                    "task_id": tid
                                }).eq("id", link_id).execute()
                                break 

                            # CASE C: Wait (40602 Queue / 40601 Handed)
                            elif status_code == 40602 or status_code == 40601:
                                status_text.write(f"‚è≥ Task {tid} processing... Status: {status_code} (Attempt {attempt+1}/{max_retries})")
                                time.sleep(retry_delay)
                                continue 

                            # CASE D: Actual Error
                            else:
                                error_msg = task_res.get('status_message', 'Unknown API Error')
                                print(f"API Error for {tid}: {error_msg}")
                                supabase.table("links").update({"status": "error"}).eq("id", link_id).execute()
                                break 

                        except Exception as e:
                            print(f"Network error polling task {tid}: {e}")
                            time.sleep(1)
                    else:
                        # Timeout
                        supabase.table("links").update({"status": "timeout"}).eq("id", link_id).execute()

            else:
                st.error(f"API Error: {res.get('status_message')}")
            
            processed += len(batch_links)
            progress_bar.progress(processed / total)
            
        except Exception as e:
            st.error(f"Global Net Error: {e}")
            time.sleep(1.5)

    # 3. Report Generation
    status_text.write(t("sending_report"))
    try:
        checked_ids = [item['id'] for item in links_data]
        res = supabase.table("links").select("url, status, is_indexed, last_check").in_("id", checked_ids).execute()
        df_report = pd.DataFrame(res.data)
        
        if not df_report.empty:
            excel_bytes = to_excel(df_report)
            date_str = datetime.now().strftime('%Y-%m-%d')
            fname = f"{report_name_prefix}_{date_str}.xlsx"
            
            msg = t("report_msg").format(report_name_prefix, total)
            send_slack_file(excel_bytes, fname, msg)
    except Exception as e:
        st.error(f"Report Generation Error: {e}")

    status_text.success(t("done"))
    time.sleep(1)
    st.rerun()
# -----------------------
# –§–£–ù–ö–¶–ò–Ø –û–¢–†–ò–°–û–í–ö–ò –ò–ù–¢–ï–†–§–ï–ô–°–ê –ü–ê–ü–ö–ò/–ü–†–û–ï–ö–¢–ê
# -----------------------
def render_link_interface(project_id, folder_id=None, folder_name=""):
    """
    –†–∏—Å—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Å—Å—ã–ª–æ–∫ –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç .xlsx, .xls, .csv
    - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –°–¢–†–û–ì–ò–ô –ø–æ—Ä—è–¥–æ–∫ —Å—Ç—Ä–æ–∫ (–∫–∞–∫ –≤ —Ñ–∞–π–ª–µ)
    - –£–º–Ω–æ –∏—â–µ—Ç –∫–æ–ª–æ–Ω–∫—É —Å —Å—Å—ã–ª–∫–æ–π (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ Referring Page)
    """
    
    # ---------------------------------------------------------
    # 1. –ó–ê–ì–†–£–ó–ö–ê –ò –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï (–°–û–†–¢–ò–†–û–í–ö–ê –ü–û –í–û–ó–†–ê–°–¢–ê–ù–ò–Æ ID)
    # ---------------------------------------------------------
    query = supabase.table("links").select("*").eq("project_id", project_id)
    
    if folder_id is None:
        query = query.is_("folder_id", "null")
    else:
        query = query.eq("folder_id", folder_id)
    
    # !!! –ì–õ–ê–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–û–†–Ø–î–ö–ê !!!
    # desc=False –æ–∑–Ω–∞—á–∞–µ—Ç "–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º". 
    # –¢–∞–∫ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∏–∑ Excel –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –ø–µ—Ä–≤–æ–π –≤ —Ç–∞–±–ª–∏—Ü–µ.
    links = query.order("id", desc=False).execute().data
    
    df = pd.DataFrame(links)

    if df.empty:
        st.info(t("empty_folder"))
    else:
        # –ú–µ—Ç—Ä–∏–∫–∏
        total = len(df)
        indexed = len(df[df['is_indexed'] == True])
        pending = len(df[df['status'] == 'pending'])
        
        m1, m2, m3, m4 = st.columns(4)
        m1.metric(t("total"), total)
        m2.metric(t("indexed"), f"{indexed} ({(indexed/total*100):.1f}%)")
        m3.metric(t("queue"), pending)
        
        with m4:
            if pending > 0:
                if st.button(t("run_queue"), type="primary", key=f"run_{folder_id}", width="stretch"):
                    to_check = df[df['status'] == 'pending'][['id', 'url']].to_dict('records')
                    run_check(to_check, report_name_prefix=f"Check_{folder_name}")
            else:
                if st.button(t("rerun_all"), key=f"rerun_{folder_id}", width="stretch"):
                    ids = df['id'].tolist()
                    supabase.table("links").update({"status": "pending", "is_indexed": None}).in_("id", ids).execute()
                    st.rerun()

        st.write("")
        # –¢–∞–±–ª–∏—Ü–∞
        selection = st.dataframe(
            df[['url', 'status', 'is_indexed', 'last_check']],
            width=None, 
            use_container_width=True,
            on_select="rerun",
            selection_mode="multi-row",
            column_config={
                "is_indexed": st.column_config.CheckboxColumn(t("col_index"), disabled=True),
                "url": st.column_config.LinkColumn(t("col_url"), display_text=None)
            }
        )
        
        # –£–¥–∞–ª–µ–Ω–∏–µ
        if len(selection.selection.rows) > 0:
            sel_idx = selection.selection.rows
            sel_ids = df.iloc[sel_idx]['id'].tolist()
            if st.button(t("del_selected").format(len(sel_ids)), key=f"del_sel_{folder_id}"):
                supabase.table("links").delete().in_("id", sel_ids).execute()
                st.rerun()

    st.divider()
    
    # ---------------------------------------------------------
    # 2. –ò–ù–¢–ï–†–§–ï–ô–° –ó–ê–ì–†–£–ó–ö–ò (XLSX / CSV)
    # ---------------------------------------------------------
    st.subheader(f"üì• Add links to '{folder_name}'")
    
    tab_text, tab_file = st.tabs(["üìù Paste List", "ep Upload Excel/CSV"])
    
    # --- –í–∫–ª–∞–¥–∫–∞ 1: –¢–µ–∫—Å—Ç ---
    with tab_text:
        text_input = st.text_area(t("paste_links"), height=150, key=f"input_{folder_id}")
        if st.button(t("save_btn"), key=f"save_txt_{folder_id}"):
            urls = parse_text_urls(text_input)
            if urls:
                data = [{"project_id": project_id, "url": u, "folder_id": folder_id, "status": "pending"} for u in urls]
                batch_size = 1000
                for i in range(0, len(data), batch_size):
                    supabase.table("links").insert(data[i:i+batch_size]).execute()
                st.success(t("success_added").format(len(urls)))
                time.sleep(1)
                st.rerun()

    # --- –í–∫–ª–∞–¥–∫–∞ 2: –§–∞–π–ª (XLSX Support) ---
    with tab_file:
        uploaded_file = st.file_uploader("Excel (.xlsx, .xls) or CSV", type=['xlsx', 'xls', 'csv'], key=f"file_{folder_id}")
        
        if uploaded_file is not None and st.button("üì§ Process File", key=f"proc_{folder_id}"):
            try:
                df_upload = None
                file_ext = uploaded_file.name.split('.')[-1].lower()
                
                # --- –ü–û–ü–´–¢–ö–ê 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Excel (xlsx) ---
                try:
                    df_upload = pd.read_excel(uploaded_file, engine='openpyxl')
                except Exception:
                    uploaded_file.seek(0) # –ü–µ—Ä–µ–º–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –≤ –Ω–∞—á–∞–ª–æ
                    
                    # --- –ü–û–ü–´–¢–ö–ê 2: –°—Ç–∞—Ä—ã–π Excel (xls) ---
                    try:
                        df_upload = pd.read_excel(uploaded_file, engine='xlrd')
                    except Exception:
                        uploaded_file.seek(0)
                        
                        # --- –ü–û–ü–´–¢–ö–ê 3: "–§–µ–π–∫–æ–≤—ã–π" Excel (HTML/XML –≤–Ω—É—Ç—Ä–∏) ---
                        # –≠—Ç–æ —Ä–µ—à–∏—Ç –≤–∞—à—É –æ—à–∏–±–∫—É "found b'<html xm'"
                        try:
                            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ HTML —Ç–∞–±–ª–∏—Ü—É
                            dfs = pd.read_html(uploaded_file)
                            if dfs:
                                df_upload = dfs[0] # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        except Exception:
                            uploaded_file.seek(0)
                            
                            # --- –ü–û–ü–´–¢–ö–ê 4: –û–±—ã—á–Ω—ã–π CSV ---
                            try:
                                df_upload = pd.read_csv(uploaded_file)
                            except Exception:
                                # –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å: CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º —Ç–æ—á–∫–∞-—Å –∑–∞–ø—è—Ç–æ–π
                                uploaded_file.seek(0)
                                try:
                                    df_upload = pd.read_csv(uploaded_file, sep=';')
                                except:
                                    pass

                if df_upload is None:
                    st.error("‚ùå Failed to read file. It might be corrupted or in an unsupported format.")
                    st.stop()

                # --- –î–ê–õ–ï–ï –í–ê–®–ê –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê –°–°–´–õ–û–ö (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
                target_col = None
                clean_cols = {c: str(c).lower().strip() for c in df_upload.columns}
                
                priority_keywords = [
                    'referring page', 'source url', 
                    'target url', 'donor', 
                    'url', 'link', 'website'
                ]
                
                for kw in priority_keywords:
                    for original_col, clean_col in clean_cols.items():
                        if kw in clean_col:
                            target_col = original_col
                            break
                    if target_col: break
                
                if not target_col:
                    target_col = df_upload.columns[0]
                    st.toast(f"‚ö†Ô∏è Column name not recognized. Using first column: '{target_col}'", icon="‚ÑπÔ∏è")

                urls_from_file = df_upload[target_col].dropna().astype(str).tolist()
                valid_urls = [u.strip() for u in urls_from_file if len(u.strip()) > 5]

                if valid_urls:
                    data = [{
                        "project_id": project_id, 
                        "url": u, 
                        "folder_id": folder_id, 
                        "status": "pending"
                    } for u in valid_urls]
                    
                    batch_size = 1000
                    for i in range(0, len(data), batch_size):
                        supabase.table("links").insert(data[i:i+batch_size]).execute()
                        
                    st.success(f"‚úÖ Success! Added {len(data)} links. Order preserved.")
                    time.sleep(1.5)
                    st.rerun()
                else:
                    st.error("‚ùå No valid URLs found in the file.")
                    
            except Exception as e:
                st.error(f"Global Error: {e}")

# ==========================================
# –°–ê–ô–î–ë–ê–† (–ò–ï–†–ê–†–•–ò–Ø)
# ==========================================
with st.sidebar:
    # --- LANGUAGE SWITCHER ---
    lang_choice = st.radio("Language / –ú–æ–≤–∞:", ["üá¨üáß English", "üá∫üá¶ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"], horizontal=True)
    if lang_choice == "üá¨üáß English":
        st.session_state.lang = "en"
    else:
        st.session_state.lang = "uk"
    
    st.divider()
    
    st.title(t("nav_title"))
    
    if st.button(t("home_btn"), width="stretch"):
        st.session_state.selected_project_id = None
        st.session_state.selected_folder_id = None
        st.rerun()
    
    st.divider()
    
    # === SAFE FETCHING FOR SIDEBAR (FIX FOR httpx.ReadError) ===
    projs = safe_fetch("projects", order_col="created_at")
    all_folders = safe_fetch("folders", order_col="name")
    
    if projs:
        st.caption(t("projects_list"))
        for p in projs:
            is_expanded = (st.session_state.selected_project_id == p['id'])
            
            with st.expander(f"üìÇ {p['name']}", expanded=is_expanded):
                
                # –ö–Ω–æ–ø–∫–∞ —Å–∞–º–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
                if st.button(t("view_proj"), key=f"dash_{p['id']}", width="stretch"):
                    st.session_state.selected_project_id = p['id']
                    st.session_state.selected_folder_id = None
                    st.rerun()

                # –ü–æ–¥–ø–∞–ø–∫–∏
                p_folders = [f for f in all_folders if f['project_id'] == p['id']]
                if p_folders:
                    for f in p_folders:
                        if st.button(f"‚îî üìÅ {f['name']}", key=f"sb_f_{f['id']}", width="stretch"):
                            st.session_state.selected_project_id = p['id']
                            st.session_state.selected_folder_id = f['id']
                            st.rerun()

    st.divider()
    with st.expander(t("create_proj_exp")):
        new_p = st.text_input(t("proj_name_placeholder"))
        if st.button(t("create_btn")):
            supabase.table("projects").insert({"name": new_p}).execute()
            st.rerun()

    if st.session_state.selected_project_id:
        st.write("")
        st.write("")
        with st.expander(t("del_proj_exp")):
            st.warning(t("warn_del_proj"))
            if st.button(t("confirm_del"), type="primary"):
                supabase.table("projects").delete().eq("id", st.session_state.selected_project_id).execute()
                st.session_state.selected_project_id = None
                st.session_state.selected_folder_id = None
                st.rerun()

# ==========================================
# –û–°–ù–û–í–ù–û–ô –≠–ö–†–ê–ù
# ==========================================

# 1. –ì–õ–ê–í–ù–ê–Ø (–î–ê–®–ë–û–†–î)
if not st.session_state.selected_project_id:
    st.title(t("dash_title"))
    
    if not projs:
        st.info(t("no_projs"))
    else:
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
        all_links = safe_fetch("links", select="id, project_id, status, is_indexed")
        df_all = pd.DataFrame(all_links)
        
        stats_data = []
        global_pending_count = 0
        
        for p in projs:
            if not df_all.empty:
                p_links = df_all[df_all['project_id'] == p['id']]
                cnt = len(p_links)
                pend = len(p_links[p_links['status'] == 'pending'])
                idx = len(p_links[p_links['is_indexed'] == True])
            else:
                cnt, pend, idx = 0, 0, 0
            
            global_pending_count += pend
            stats_data.append({
                t("project"): p['name'],
                t("links_count"): cnt,
                t("in_index"): idx,
                t("in_queue"): pend
            })
        
        m1, m2 = st.columns(2)
        m1.metric(t("total_projs"), len(projs))
        m2.metric(t("total_queue"), global_pending_count)

        st.dataframe(pd.DataFrame(stats_data), width="stretch", hide_index=True)
        st.divider()
        
        if global_pending_count > 0:
            st.warning(t("ready_global").format(global_pending_count))
            if st.button(t("run_global"), type="primary", width="stretch"):
                 pending_full = supabase.table("links").select("id, url").eq("status", "pending").execute().data
                 run_check(pending_full, report_name_prefix="Global_Check")
        else:
            st.success(t("queue_empty"))
            st.write("")
            if st.button(t("reset_global")):
                supabase.table("links").update({"status": "pending", "is_indexed": None}).neq("id", 0).execute()
                st.rerun()

# 2. –í–ù–£–¢–†–ò –ü–†–û–ï–ö–¢–ê
elif st.session_state.selected_project_id:
    curr_proj = next(p for p in projs if p['id'] == st.session_state.selected_project_id)
    
    # –°–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ —ç—Ç–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    p_folders = [f for f in all_folders if f['project_id'] == curr_proj['id']]

    # 2.1 –ï–°–õ–ò –ú–´ –í–´–ë–†–ê–õ–ò –ö–û–ù–ö–†–ï–¢–ù–£–Æ –ü–ê–ü–ö–£
    if st.session_state.selected_folder_id is not None:
        f_obj = next((f for f in p_folders if f['id'] == st.session_state.selected_folder_id), None)
        if not f_obj:
            st.error("Folder not found")
            st.session_state.selected_folder_id = None
            st.rerun()
        
        col_back, col_title = st.columns([1, 5])
        with col_back:
            if st.button(t("back_to_proj")):
                st.session_state.selected_folder_id = None
                st.rerun()
        with col_title:
            st.title(f"{curr_proj['name']} / üìÇ {f_obj['name']}")
        
        # –†–µ–Ω–¥–µ—Ä —Ç–∞–±–ª–∏—Ü—ã –∏ –∫–Ω–æ–ø–æ–∫ –¥–ª—è –≠–¢–û–ô –ø–∞–ø–∫–∏
        render_link_interface(curr_proj['id'], f_obj['id'], f_obj['name'])

    # 2.2 –ï–°–õ–ò –ú–´ –í –ö–û–†–ù–ï –ü–†–û–ï–ö–¢–ê
    else:
        st.title(f"üìÇ {curr_proj['name']}")
        
        # –ï—Å–ª–∏ –ï–°–¢–¨ –ø–∞–ø–∫–∏ -> –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
        if p_folders:
            st.caption(t("folder_struct"))
            
            links_res = supabase.table("links").select("folder_id, status, is_indexed").eq("project_id", curr_proj['id']).execute()
            df_links = pd.DataFrame(links_res.data)
            
            for f in p_folders:
                if not df_links.empty:
                    f_links = df_links[df_links['folder_id'] == f['id']]
                    total = len(f_links)
                    indexed = len(f_links[f_links['is_indexed'] == True])
                else:
                    total, indexed = 0, 0
                
                with st.container(border=True):
                    c1, c2, c3 = st.columns([3, 1, 0.5]) 
                    with c1:
                        st.subheader(f"üìÅ {f['name']}")
                        st.caption(f"{t('total')}: {total} | {t('indexed')}: {indexed}")
                    with c2:
                        st.write("")
                        if st.button(t("open_btn"), key=f"open_card_{f['id']}", width="stretch"):
                            st.session_state.selected_folder_id = f['id']
                            st.rerun()
                    with c3:
                        st.write("")
                        if st.button(t("del_btn"), key=f"del_f_{f['id']}"):
                            supabase.table("folders").delete().eq("id", f['id']).execute()
                            st.rerun()
            
            st.divider()
            with st.popover(t("add_new_folder")):
                new_f_name = st.text_input(t("folder_name"))
                if st.button(t("create_folder_btn")):
                    supabase.table("folders").insert({"name": new_f_name, "project_id": curr_proj['id']}).execute()
                    st.rerun()

        # –ï—Å–ª–∏ –ü–ê–ü–û–ö –ù–ï–¢ -> –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
        else:
            st.info(t("flat_mode"))
            
            with st.popover(t("create_first_folder")):
                new_f_name = st.text_input(t("folder_name"))
                if st.button(t("create_folder_btn")):
                    supabase.table("folders").insert({"name": new_f_name, "project_id": curr_proj['id']}).execute()
                    st.rerun()
            
            st.divider()
            render_link_interface(curr_proj['id'], None, t("root_folder"))
